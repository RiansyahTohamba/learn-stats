{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413 kalimat dengan PartOfSpeech TAG\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# sent singkatan dari sentences\n",
    "def ie_preprocess(document):\n",
    "#     1. segmenter [1],\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "# 2. word tokenizer [2]\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "# 3. part-of-speech tagger [3]:\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]    \n",
    "    return sentences\n",
    "# sisa tahap 4 dan 5\n",
    "alvesSentences = ie_preprocess(open('papers/alves2010.txt').read())\n",
    "print(len(alvesSentences), 'kalimat dengan PartOfSpeech TAG')\n",
    "# writing file nya di tulis_paper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.tree.Tree"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# koding buat NAMED ENTITY RECONITION ?\n",
    "# NLTK dilengkapi classifier utk recognize named-entity\n",
    "# nltk.ne_chunk(sent, binary=True)\n",
    "sent = nltk.corpus.treebank.tagged_sents()[22]\n",
    "type(nltk.ne_chunk(sent))\n",
    "# dicetak di tree.txt saja\n",
    "# If we set the parameter binary=True [1], then named entities are just tagged as NE; otherwise, the classifier adds category labels such as PERSON, ORGANIZATION, and GPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('A', 'DT')\n",
      "1 ('wide', 'JJ')\n",
      "2 ('variety', 'NN')\n",
      "3 ('of', 'IN')\n",
      "4 ('software', 'NN')\n",
      "5 ('metrics', 'NNS')\n",
      "6 ('have', 'VBP')\n",
      "7 ('been', 'VBN')\n",
      "8 ('proposed', 'VBN')\n",
      "9 ('and', 'CC')\n",
      "10 ('a', 'DT')\n",
      "11 ('broad', 'JJ')\n",
      "12 ('range', 'NN')\n",
      "13 ('of', 'IN')\n",
      "14 ('tools', 'NNS')\n",
      "15 ('is', 'VBZ')\n",
      "16 ('available', 'JJ')\n",
      "17 ('to', 'TO')\n",
      "18 ('measure', 'VB')\n",
      "19 ('them', 'PRP')\n",
      "20 ('.', '.')\n"
     ]
    }
   ],
   "source": [
    "first_sente = alvesSentences[0]\n",
    "role = alvesSentences[0][0][1]\n",
    "word = alvesSentences[0][0][0]\n",
    "for idx, val in enumerate(first_sente):\n",
    "    if(role == 'VBN'):\n",
    "        print(word)\n",
    "    print(idx, val)        \n",
    "# for idx in range(4):\n",
    "#     if(role == 'VBN'):\n",
    "#         print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A wide variety of software metrics have been proposed and a broad range of tools is available to measure them.\n",
      "However, the effective use of software metrics is hindered by the lack of meaningful thresholds.\n",
      "Thresholds have been proposed for a few metrics only, mostly based on expert opinion and a small number of observations.\n",
      "Previously proposed methodologies for systematically deriving metric thresholds have made unjustiÔ¨Åed assumptions about the statistical properties of source code metrics.\n",
      "[('A', 'DT'), ('wide', 'JJ'), ('variety', 'NN'), ('of', 'IN'), ('software', 'NN'), ('metrics', 'NNS'), ('have', 'VBP'), ('been', 'VBN'), ('proposed', 'VBN'), ('and', 'CC'), ('a', 'DT'), ('broad', 'JJ'), ('range', 'NN'), ('of', 'IN'), ('tools', 'NNS'), ('is', 'VBZ'), ('available', 'JJ'), ('to', 'TO'), ('measure', 'VB'), ('them', 'PRP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(open('papers/alves2010.txt').read())\n",
    "for idx in range(4):\n",
    "    print(sentences[idx])\n",
    "# for idx in range(4):\n",
    "#     print(sentences[idx])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "# alvesSentences[1]\n",
    "nltk.help.upenn_tagset()\n",
    "# nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6e3d2983f7bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mIN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'.*\\bin\\b(?!\\b.+ing)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mieer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsed_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NYT_19980315'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_rels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ORG'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LOC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ieer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "# The following example searches for strings that contain the word in. The special regular expression (?!\\b.+ing\\b) is a negative lookahead assertion that allows us to disregard strings such as success in supervising the transition of, where in is followed by a gerund.\n",
    "IN = re.compile(r'.*\\bin\\b(?!\\b.+ing)')\n",
    "for doc in nltk.corpus.ieer.parsed_docs('NYT_19980315'):\n",
    "    for rel in nltk.sem.extract_rels('ORG', 'LOC', doc,corpus='ieer', pattern = IN):\n",
    "        print(nltk.sem.rtuple(rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "text = '''\n",
    "he PRP B-NP\n",
    "accepted VBD B-VP\n",
    "the DT B-NP\n",
    "position NN I-NP\n",
    "of IN B-PP\n",
    "vice NN B-NP\n",
    "chairman NN I-NP\n",
    "of IN B-PP\n",
    "Carlyle NNP B-NP\n",
    "Group NNP I-NP\n",
    ", , O\n",
    "a DT B-NP\n",
    "merchant NN I-NP\n",
    "banking NN I-NP\n",
    "concern NN I-NP\n",
    ". . O\n",
    "'''\n",
    "nltk.chunk.conllstr2tree(text, chunk_types=['NP']).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP the/DT little/JJ yellow/JJ dog/NN)\n",
      "  barked/VBD\n",
      "  at/IN\n",
      "  (NP the/DT cat/NN))\n"
     ]
    }
   ],
   "source": [
    "sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"), (\"dog\", \"NN\"), (\"barked\", \"VBD\"), (\"at\", \"IN\"), (\"the\", \"DT\"), (\"cat\", \"NN\")]\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(sentence)\n",
    "print(result)\n",
    "result.draw()\n",
    "# (S\n",
    "#  (NP the/DT little/JJ yellow/JJ dog/NN)\n",
    "#  barked/VBD\n",
    "#  at/IN\n",
    "#  (NP the/DT cat/NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToText(paper):\n",
    "    # raw/str -> token/list -> convert ke nltk.Text    \n",
    "    raw = paper.read()    \n",
    "    # type(raw) == string    \n",
    "    tokens = nltk.word_tokenize(raw)\n",
    "    # type(tokens) == list    \n",
    "    # token bisa berupa tanda-baca{?.,etc}, pos = {adverb,adj,}    \n",
    "    return nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 23 of 23 matches:\n",
      "t is essential to deÔ¨Åne meaningful threshold values . These have been deÔ¨Åned fo\n",
      " . For example , McCabe proposed a threshold value of 10 for his complexity met\n",
      "inable and untestable [ 1 ] . This threshold was inspired by experience in a pa\n",
      " present a method to derive metric threshold values empirically from the measur\n",
      "McCabe metric 10 was deÔ¨Åned as the threshold [ 1 ] , and for the NPATH metric 2\n",
      "NPATH metric 200 was deÔ¨Åned as the threshold [ 5 ] . Above these values , metho\n",
      "andard deviation ( œÉ ) to derive a threshold T from project data . A threshold \n",
      " threshold T from project data . A threshold T is calculated as T = ¬µ + œÉ or T \n",
      " normal distributions ) . A metric threshold T can œÉ , where k is the number of\n",
      "ity models are compared , one with threshold and one without . For the model wi\n",
      "d one without . For the model with threshold , zero probability of error exists\n",
      "exists for metric values below the threshold . The authors conclude that there \n",
      "evidence supporting the model with threshold as there is no signiÔ¨Åcant differen\n",
      "c values higher or lower a speciÔ¨Åc threshold ( resembling a U-shape ) . The stu\n",
      "e is no empirical evidence for the threshold model used to predict faults . How\n",
      "ze ( 48 % ) . IV . BENCHMARK-BASED THRESHOLD DERIVATION The methodology propose\n",
      "or the McCabe metric , the derived threshold is 14 . This threshold is meaningf\n",
      "the derived threshold is 14 . This threshold is meaningful , since not only it \n",
      "choosing a quantile for deriving a threshold . Choosing a quantile for which th\n",
      "ty ( e.g . 20 % ) will result in a threshold which will not allow to distinguis\n",
      " complexity , will result in lower threshold values . On the other hand , the e\n",
      "complexity , will result in higher threshold values . Hence , it is extremely i\n",
      "ts in our methodology for deriving threshold were analyzed as well as threats t\n"
     ]
    }
   ],
   "source": [
    "# A concordance view shows us every occurrence of a given word, together with some context. \n",
    "alvesText = convertToText(open('papers/alves2010.txt'))\n",
    "alvesText.concordance('threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 82 matches:\n",
      "indered by the lack of meaningful thresholds . Thresholds have been proposed f\n",
      "e lack of meaningful thresholds . Thresholds have been proposed for a few metr\n",
      "or systematically deriving metric thresholds have made unjustiÔ¨Åed assumptions \n",
      "eral applicability of the derived thresholds is jeopardized . We designed a me\n",
      "d a method that determines metric thresholds empirically from measurement data\n",
      "pooled and aggregated after which thresholds are selected that ( i ) bring out\n",
      "etary and open-source , to derive thresholds for metrics included in the SIG m\n",
      "y applicable . For most metrics , thresholds are lacking or do not generalize \n",
      "Ô¨Årst pooled and aggregated . Then thresholds are determined that ( i ) bring o\n",
      " in mind to avoid the problems of thresholds based on expert opinion and of ea\n",
      "aches to systematic derivation of thresholds . 1 ) The method should not be dr\n",
      " of earlier attempts to determine thresholds . Section III demonstrates the us\n",
      "ction III demonstrates the use of thresholds derived through our method , taki\n",
      "previous attempts to deÔ¨Åne metric thresholds . We start by describing works wh\n",
      "e start by describing works where thresholds are deÔ¨Åned by experience . Then ,\n",
      " detail methodologies that derive thresholds based on data analysis , which ar\n",
      "w about methodologies that derive thresholds based on error information and fr\n",
      "ethodology was designed to derive thresholds from benchmark data and such is r\n",
      "use 100 Java and C # systems . A. Thresholds derived from experience C. Thresh\n",
      "sholds derived from experience C. Thresholds using error models Many authors d\n",
      "models Many authors deÔ¨Åned metric thresholds according to their experience . F\n",
      " metric , 65 and 85 are deÔ¨Åned as thresholds [ 6 ] . Methods whose metric valu\n",
      " to dispute about the values . B. Thresholds from metric analysis ‚àí Erni et al\n",
      "ristic ( ROC ) method to identify thresholds to predict the existence of bugs \n",
      "tnawi et al . were able to derive thresholds to predict errors , there are two\n"
     ]
    }
   ],
   "source": [
    "# dibedakan dengan threshold vs thresholds = noun vs noun+s\n",
    "alvesText.concordance('thresholds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric method paper distribution metrics thresholds code distributions\n",
      "size mccabe quality section methodology results mean chidamber\n",
      "performance sample box quantile\n",
      "\n",
      "pakai \"s\" jadi jamak\n",
      "we the code systems benchmark technique quantiles metrics use metric\n",
      "that empirically variability distributions values criteria threshold\n",
      "scale distribution analyze\n"
     ]
    }
   ],
   "source": [
    "# What other words appear in a similar range of contexts? We can find out by appending the term similar to the name of the text in question, then inserting the relevant word in parentheses:\n",
    "# noun vs noun+s wkwkwk \n",
    "## gimana cara deteksi phrases/frasa? apakah masalah besar? tidak apa-apa\n",
    "# box = box plot\n",
    "# chidamber  = chidamber kemerer\n",
    "# similar? = Distributional similarity: find other words which appear in the same contexts as the specified word; list most similar words first.\n",
    "alvesText.similar('threshold')\n",
    "print('')\n",
    "print('pakai \"s\" jadi jamak')\n",
    "alvesText.similar('thresholds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a3d58b4eaeee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0malvesSentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mie_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'papers/alves2010.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malvesSentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-a3d58b4eaeee>\u001b[0m in \u001b[0;36mie_preprocess\u001b[0;34m(document)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mie_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "def ie_preprocess(document):\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]    \n",
    "    return sentences\n",
    "\n",
    "alvesSentences = ie_preprocess(open('papers/alves2010.txt').read())\n",
    "len(alvesSentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
