{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ide target \n",
    "\n",
    "## alur\n",
    "<ol>    \n",
    "    <li>entity detection</li>\n",
    "    <li>Named Entity</li>\n",
    "    <li>relation extraction</li>\n",
    "</ol>    \n",
    "\n",
    "## pos tagging\n",
    "\n",
    "\n",
    "\n",
    "## entity detection\n",
    "\n",
    "bagaimana caranya? <br>\n",
    "<ol>    \n",
    "    <li>NP chunking</li>    \n",
    "    <ol>\n",
    "        <li>unggul di :</li>\n",
    "    </ol>\n",
    "    <li>Tag Patterns, unggul di?</li>\n",
    "    <li>Chunking with Regular Expressions , unggul di?</li>\n",
    "    <li>Exploring Text Corpora?</li>\n",
    "    function label() untuk menunjukkan role nya\n",
    "    \t<p>\n",
    ">>> cp = nltk.RegexpParser('CHUNK: {<V.*> <TO> <V.*>}')\n",
    ">>> brown = nltk.corpus.brown\n",
    ">>> for sent in brown.tagged_sents():\n",
    "...     tree = cp.parse(sent)\n",
    "...     for subtree in tree.subtrees():\n",
    "...         if subtree.label() == 'CHUNK': print(subtree)\n",
    "            </p>\n",
    "    <li>Chinking </li>\n",
    "    <li>Representing chunks : tags vs trees </li>    \n",
    "</ol>\n",
    "<br>\n",
    "\n",
    "\n",
    "## Named entity recognition\n",
    "\n",
    "\n",
    "\n",
    "## ide html conversation\n",
    "mengubah paper menjadi tampilan html? <br>\n",
    "jadi lebih indah hehe <br>\n",
    "ubah sentences menjadi seperti ini ? <br>\n",
    "bio : hai? <br>\n",
    "rian : ya ada apa? <br>\n",
    "fathan : ok  deh <br>\n",
    "tidak signifikan ya?\n",
    "\n",
    "## ide html variatey color\n",
    "Subject - Verb - Object <br>\n",
    "export ke html, svo ditandai dengan warna warni <br>\n",
    "\n",
    "### gimana caranya export html?\n",
    "sementara ini dengan print string yang mengandung tag html \n",
    "\n",
    "## ide yang ditunda dulu\n",
    "ch 8 subtitusi dengan CFG dan ch 9 feature based grammar sbg input ch 10 inferensial serta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Semantic Interpretation Package\n",
    "\n",
    "This package contains classes for representing semantic structure in\n",
    "formulas of first-order logic and for evaluating such formulas in\n",
    "set-theoretic models.\n",
    "\n",
    "    >>> from nltk.sem import logic\n",
    "    >>> logic._counter._value = 0\n",
    "\n",
    "The package has two main components:\n",
    "\n",
    " - ``logic`` provides support for analyzing expressions of First\n",
    "   Order Logic (FOL).\n",
    " - ``evaluate`` allows users to recursively determine truth in a\n",
    "   model for formulas of FOL.\n",
    "\n",
    "A model consists of a domain of discourse and a valuation function,\n",
    "which assigns values to non-logical constants. We assume that entities\n",
    "in the domain are represented as strings such as ``'b1'``, ``'g1'``,\n",
    "etc. A ``Valuation`` is initialized with a list of (symbol, value)\n",
    "pairs, where values are entities, sets of entities or sets of tuples\n",
    "of entities.\n",
    "The domain of discourse can be inferred from the valuation, and model\n",
    "is then created with domain and valuation as parameters.\n",
    "\n",
    "    >>> from nltk.sem import Valuation, Model\n",
    "    >>> v = [('adam', 'b1'), ('betty', 'g1'), ('fido', 'd1'),\n",
    "    ... ('girl', set(['g1', 'g2'])), ('boy', set(['b1', 'b2'])),\n",
    "    ... ('dog', set(['d1'])),\n",
    "    ... ('love', set([('b1', 'g1'), ('b2', 'g2'), ('g1', 'b1'), ('g2', 'b1')]))]\n",
    "    >>> val = Valuation(v)\n",
    "    >>> dom = val.domain\n",
    "    >>> m = Model(dom, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.sem?\n",
    "# nltk.sem.extract_rels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ORG: 'WHYY'] 'in' [LOC: 'Philadelphia']\n",
      "[ORG: 'McGlashan &AMP; Sarrail'] 'firm in' [LOC: 'San Mateo']\n",
      "[ORG: 'Freedom Forum'] 'in' [LOC: 'Arlington']\n",
      "[ORG: 'Brookings Institution'] ', the research group in' [LOC: 'Washington']\n",
      "[ORG: 'Idealab'] ', a self-described business incubator based in' [LOC: 'Los Angeles']\n",
      "[ORG: 'Open Text'] ', based in' [LOC: 'Waterloo']\n",
      "[ORG: 'WGBH'] 'in' [LOC: 'Boston']\n",
      "[ORG: 'Bastille Opera'] 'in' [LOC: 'Paris']\n",
      "[ORG: 'Omnicom'] 'in' [LOC: 'New York']\n",
      "[ORG: 'DDB Needham'] 'in' [LOC: 'New York']\n",
      "[ORG: 'Kaplan Thaler Group'] 'in' [LOC: 'New York']\n",
      "[ORG: 'BBDO South'] 'in' [LOC: 'Atlanta']\n",
      "[ORG: 'Georgia-Pacific'] 'in' [LOC: 'Atlanta']\n"
     ]
    }
   ],
   "source": [
    "# variable re. dari mana?\n",
    "import re\n",
    "# coba hindari-gerund.txt untuk belajar regex berikut\n",
    "IN = re.compile(r'.*\\bin\\b(?!\\b.+ing)')\n",
    "for doc in nltk.corpus.ieer.parsed_docs('NYT_19980315'):\n",
    "    for rel in nltk.sem.extract_rels('ORG', 'LOC', doc,corpus='ieer', pattern = IN):\n",
    "        print(nltk.sem.rtuple(rel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. sentece segmentation <br>\n",
    "input = raw (string)\n",
    "2. tokenization <br>\n",
    "input = sentences (list[string-1,string-2,..,string-n])\n",
    "3. part of speech tagging <br>\n",
    "input = list of lists of strings = list[list1[string1,..,string-n],list1[string1,..,string-n)] <br>\n",
    "output = sentences dengan pos (list of lists of tuples)\n",
    "4. entity detection <br>\n",
    "input = sentences dengan pos (list of lists of tuples)\n",
    "5. relation detection <br>\n",
    "input = list of trees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
